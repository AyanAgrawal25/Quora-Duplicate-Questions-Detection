{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "yZ0jrztrCWcz"
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import re\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import Model\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "id": "Z-xd5R25Ee66",
    "outputId": "f828306c-539d-44f9-fb1f-441b16b5464e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
       "      <td>What would happen if the Indian government sto...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>How can I increase the speed of my internet co...</td>\n",
       "      <td>How can Internet speed be increased by hacking...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
       "      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
       "      <td>Which fish would survive in salt water?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  qid1  ...                                          question2 is_duplicate\n",
       "0   0     1  ...  What is the step by step guide to invest in sh...            0\n",
       "1   1     3  ...  What would happen if the Indian government sto...            0\n",
       "2   2     5  ...  How can Internet speed be increased by hacking...            0\n",
       "3   3     7  ...  Find the remainder when [math]23^{24}[/math] i...            0\n",
       "4   4     9  ...            Which fish would survive in salt water?            0\n",
       "\n",
       "[5 rows x 6 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('smai_project/train.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "Qu3f44FjES0N"
   },
   "outputs": [],
   "source": [
    "MAX_NB_WORDS = 200000\n",
    "tokenizer = Tokenizer(num_words = MAX_NB_WORDS)\n",
    "tokenizer.fit_on_texts(list(df['question1'].values.astype(str))+list(df['question2'].values.astype(str)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "tjN0VyMXETvq"
   },
   "outputs": [],
   "source": [
    "word_index = tokenizer.word_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h-2UmIvhEo7-"
   },
   "source": [
    "Embedding Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "wIQjbYHDEIkQ"
   },
   "outputs": [],
   "source": [
    "embedding_index = {}\n",
    "with open('smai_project/glove.840B.300d.txt','r') as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = ''.join(values[:-300])   \n",
    "        vectors = np.asarray(values[-300:], dtype='float32')\n",
    "        embedding_index[word] = vectors\n",
    "    f.close()\n",
    "embedding_matrix = np.random.random((len(word_index)+1, 300))\n",
    "for word, i in word_index.items():\n",
    "    if embedding_index.get(word) is not None:\n",
    "        embedding_matrix[i] = embedding_index.get(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X63GfkR5Es6v"
   },
   "source": [
    "Processing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "ARFR5Mfdoamt"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "y = df['is_duplicate']\n",
    "X_train,X_test,y_train,y_test = train_test_split(df,y, test_size = float(3/10), random_state =0)\n",
    "X_valid,X_test,y_valid,y_test = train_test_split(X_test,y_test, test_size = float(1/3), random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "A6tHD2IiFNAt"
   },
   "outputs": [],
   "source": [
    "X_train_q1 = tokenizer.texts_to_sequences(X_train['question1'].values.astype(str))\n",
    "X_train_q2 = tokenizer.texts_to_sequences(X_train['question2'].values.astype(str))\n",
    "\n",
    "X_train_q1 = pad_sequences(X_train_q1, maxlen = 30, padding='post')\n",
    "X_train_q2 = pad_sequences(X_train_q2, maxlen = 30, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "8_Io6-07GnRx"
   },
   "outputs": [],
   "source": [
    "X_valid_q1 = tokenizer.texts_to_sequences(X_valid['question1'].values.astype(str))\n",
    "X_valid_q2 = tokenizer.texts_to_sequences(X_valid['question2'].values.astype(str))\n",
    "\n",
    "X_valid_q1 = pad_sequences(X_valid_q1, maxlen = 30, padding='post')\n",
    "X_valid_q2 = pad_sequences(X_valid_q2, maxlen = 30, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "xRoyZMWCFUTC"
   },
   "outputs": [],
   "source": [
    "X_test_q1 = tokenizer.texts_to_sequences(X_test['question1'].values.astype(str))\n",
    "X_test_q2 = tokenizer.texts_to_sequences(X_test['question2'].values.astype(str))\n",
    "\n",
    "X_test_q1 = pad_sequences(X_test_q1, maxlen = 30, padding='post')\n",
    "X_test_q2 = pad_sequences(X_test_q2, maxlen = 30, padding='post')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r-VpW9HhI7Zx"
   },
   "source": [
    "LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "zs8iqEupI6xk"
   },
   "outputs": [],
   "source": [
    "# Model for Q1\n",
    "q1_model = tf.keras.Sequential()\n",
    "q1_model.add(Embedding(input_dim = len(word_index)+1,output_dim = 300,input_length = 30,weights = [embedding_matrix]))\n",
    "q1_model.add(LSTM(128, activation = 'tanh', return_sequences = True))\n",
    "q1_model.add(Dropout(0.1))\n",
    "q1_model.add(LSTM(128, return_sequences = True))\n",
    "q1_model.add(LSTM(128))\n",
    "q1_model.add(Dense(60, activation = 'tanh'))\n",
    "q1_model.add(Dense(2, activation = 'sigmoid'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "D6Ns5yXRJEkQ"
   },
   "outputs": [],
   "source": [
    "# Model for Q2\n",
    "q2_model = tf.keras.Sequential()\n",
    "q2_model.add(Embedding(input_dim = len(word_index)+1,output_dim = 300,input_length = 30,weights = [embedding_matrix]))\n",
    "q2_model.add(LSTM(128, activation = 'tanh', return_sequences = True))\n",
    "q2_model.add(Dropout(0.1))\n",
    "q2_model.add(LSTM(128, return_sequences = True))\n",
    "q2_model.add(LSTM(128))\n",
    "q2_model.add(Dense(60, activation = 'tanh'))\n",
    "q2_model.add(Dense(2, activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "udI0yzVIJZA6"
   },
   "outputs": [],
   "source": [
    "# Merging the output of the two models\n",
    "merged = concatenate([q1_model.output, q2_model.output])\n",
    "merged = Flatten()(merged)\n",
    "merged = Dense(60, activation = 'tanh')(merged)\n",
    "merged = Dropout(0.1)(merged)\n",
    "merged = Dense(50, activation = 'relu')(merged)\n",
    "merged = Dropout(0.1)(merged)\n",
    "merged = Dense(2, activation = 'sigmoid')(merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cmcfO8wHJpUx",
    "outputId": "cb44b170-e39e-482a-ed4f-878d20927967"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "142/142 [==============================] - 1283s 9s/step - loss: 0.5769 - accuracy: 0.6941\n",
      "Epoch 2/5\n",
      "142/142 [==============================] - 1256s 9s/step - loss: 0.4932 - accuracy: 0.7649\n",
      "Epoch 3/5\n",
      "142/142 [==============================] - 1270s 9s/step - loss: 0.4494 - accuracy: 0.7908\n",
      "Epoch 4/5\n",
      "142/142 [==============================] - 1259s 9s/step - loss: 0.4111 - accuracy: 0.8115\n",
      "Epoch 5/5\n",
      "142/142 [==============================] - 1256s 9s/step - loss: 0.3762 - accuracy: 0.8300\n"
     ]
    }
   ],
   "source": [
    "lstm = Model([q1_model.input, q2_model.input], merged)\n",
    "lstm.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy',metrics = ['accuracy'])\n",
    "history = lstm.fit([X_train_q1,X_train_q2],y_train, batch_size = 2000, epochs = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y0-TxHDdi_Xb"
   },
   "source": [
    "Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9go56lHLGtNM",
    "outputId": "1f224431-9926-4679-ee12-6f8d14b2d78f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 115s 3s/step - loss: 0.4950 - accuracy: 0.7733\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7732691764831543"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = lstm.evaluate([X_valid_q1, X_valid_q2],y_valid,batch_size=2000,verbose=1)\n",
    "score[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XeM9WgpJMcFa",
    "outputId": "3d1a2336-067a-46d1-fedc-1c75ebedf141"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 56s 3s/step - loss: 0.5016 - accuracy: 0.7701\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7701154947280884"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = lstm.evaluate([X_test_q1, X_test_q2],y_test,batch_size=2000,verbose=1)\n",
    "score[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ITtOSLPGi8cA"
   },
   "source": [
    "F-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wJgvOHadjcrH",
    "outputId": "732819d7-7397-40d9-bd3b-c11f55586cc5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 112s 3s/step\n",
      "0.6861271379410707\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "y_pred = lstm.predict([X_valid_q1, X_valid_q2], batch_size=2000, verbose=1)\n",
    "y_pred_class=np.argmax(y_pred,axis=1)\n",
    "f1 = f1_score(y_valid, y_pred_class)\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s2ox7rQgiSEG",
    "outputId": "b032c4d7-0592-411a-a6ac-326482d05045"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 56s 3s/step\n",
      "0.6809474768280123\n"
     ]
    }
   ],
   "source": [
    "y_pred = lstm.predict([X_test_q1, X_test_q2], batch_size=2000, verbose=1)\n",
    "y_pred_class=np.argmax(y_pred,axis=1)\n",
    "f1 = f1_score(y_test, y_pred_class)\n",
    "print(f1)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "LSTM.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
